

# Detailed Documentation for the Antenna Model Prediction Pipeline

This code implements a full machine learning pipeline to train, evaluate, and deploy an artificial neural network (ANN) model for an antenna model. It includes data loading and preprocessing, model definition and training, evaluation with visualization, and finally generating predictions (and saving them). The code also leverages MLflow for experiment tracking and joblib for saving the data scaler.

---

## 1. Import Statements and Global Settings

```python
import os
import warnings
import re
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, Input
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras.regularizers import l1_l2
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import RobustScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
import mlflow
import joblib
```

### Explanation:
- **os, warnings:**
  Used to set environment variables and suppress unwanted warnings (for example, to quiet TensorFlow logs).

- **re:**
  Provides regular expression support; used later for cleaning up frequency strings.

- **numpy & pandas:**
  Fundamental libraries for numerical operations and data manipulation.

- **TensorFlow and Keras modules:**
  Used for building, training, and saving the deep learning model (with layers, optimizers, callbacks, and regularizers).

- **scikit-learn modules:**
  Used for splitting the dataset, scaling features, and evaluating the model using metrics like R², MAE, and MSE.

- **matplotlib and seaborn:**
  For plotting and visualizing performance metrics and relationships between features.

- **scipy.stats:**
  Used to compute the z‑score for outlier removal.

- **mlflow:**
  Used to track experiments, log metrics, and save models in a reproducible way.

- **joblib:**
  Used to save (and later load) the feature scaler to ensure consistency in preprocessing for training and prediction.

### Global Settings:
```python
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.filterwarnings("ignore")
```
- **TF_CPP_MIN_LOG_LEVEL:**
  Suppresses TensorFlow info/warning messages to keep output clean.

- **warnings.filterwarnings("ignore"):**
  Prevents Python from displaying non-critical warnings.

---

## 2. Configuration Parameters

```python
class Config:
    SEED = 42
    TEST_SIZE = 0.20
    VAL_SIZE = 0.10
    EPOCHS = 50
    BATCH_SIZE = 128
    EARLY_STOPPING_PATIENCE = 10
    REDUCE_LR_PATIENCE = 5
    REGULARIZATION = l1_l2(l1=1e-5, l2=1e-4)
    FEATURE_COLS = ["l_s", "l_2", "l_1", "s_2", "s_1", "w_s", "w_2", "w_1", "freq"]
    TARGET_COLS = ["dB(S(1,1))", "dB(S(2,1))"]
    CHECKPOINT_PATH = "best_model.h5"
```

### Explanation:
- **SEED:**
  Ensures reproducibility by setting a constant seed for random number generators.

- **TEST_SIZE & VAL_SIZE:**
  Define the fraction of the data reserved for testing and validation respectively.

- **EPOCHS & BATCH_SIZE:**
  Standard training parameters controlling how many epochs the model trains for and the batch size for gradient updates.

- **EARLY_STOPPING_PATIENCE & REDUCE_LR_PATIENCE:**
  Patience parameters used in callbacks to prevent overfitting by stopping training early or reducing learning rate when progress stalls.

- **REGULARIZATION:**
  L1 and L2 regularization are applied to the network weights to reduce overfitting.

- **FEATURE_COLS and TARGET_COLS:**
  Specify the column names for input features and target outputs, respectively. Here, the features include various physical dimensions (l, s, w values) plus the frequency, and the targets are dB values.

- **CHECKPOINT_PATH:**
  Specifies the filename for saving the best model during training.

---

## 3. Reproducibility

```python
np.random.seed(Config.SEED)
tf.random.set_seed(Config.SEED)
```

### Explanation:
- Sets the random seeds for both NumPy and TensorFlow so that model training and data splits are reproducible across runs.

---

## 4. Data Loading and Preprocessing

### 4.1. Parsing Frequency Strings

```python
def parse_frequency(freq_str):
    """Convert a frequency string with a unit (MHz or GHz) into a numeric value in MHz."""
    import re
    if not isinstance(freq_str, str):
        try:
            return float(freq_str)
        except Exception:
            return np.nan

    freq_str = freq_str.replace("\xa0", " ").strip().strip('"').strip("'")
    lower_str = freq_str.lower()

    numeric_part = re.sub(r'[^0-9\.]', '', freq_str)
    if numeric_part == "":
        parts = freq_str.split()
        if parts:
            try:
                number = float(parts[0])
            except ValueError:
                return np.nan
        else:
            return np.nan
    else:
        try:
            number = float(numeric_part)
        except ValueError:
            return np.nan

    if "ghz" in lower_str:
        return number * 1000  # Convert GHz to MHz.
    elif "mhz" in lower_str:
        return number
    else:
        return number
```

### Explanation:
- **Purpose:**
  Cleans and converts frequency values from strings like `"800.0 MHz"` or `"1.000 GHz"` into numeric values in MHz.
- **Steps:**
  - Checks if the input is a string.
  - Removes non-breaking spaces and extra quotes.
  - Uses regular expressions to strip away non-numeric characters.
  - Determines if the unit is GHz (multiplies by 1000) or MHz (keeps as is).
  - Returns `np.nan` if conversion fails.

### 4.2. Loading CSV Data

```python
def load_data(path, is_generated=False):
    """Load CSV with proper column handling."""
    if is_generated:
        df = pd.read_csv(path, delimiter=",")
        if "ID" in df.columns:
            df = df.drop(columns=["ID"])
    else:
        df = pd.read_csv(
            path,
            skiprows=1,
            header=None,
            names=Config.FEATURE_COLS + Config.TARGET_COLS
        )
    df["freq"] = df["freq"].apply(parse_frequency)
    df["freq"] = pd.to_numeric(df["freq"], errors='coerce')
    if not is_generated:
        numeric_cols = Config.FEATURE_COLS + Config.TARGET_COLS
        z = np.abs(stats.zscore(df[numeric_cols]))
        df = df[(z < 3).all(axis=1)]
    return df
```

### Explanation:
- **is_generated Flag:**
  The function can handle two types of files:
  - **Training Data:**
    Assumes no header and uses the defined feature and target columns after skipping a metadata row.
  - **Generated Data:**
    Uses the header in the file, drops the "ID" column if present, and expects fewer columns.
- **Frequency Processing:**
  Every frequency entry is passed through the `parse_frequency` function and converted to a numeric type.
- **Outlier Removal:**
  For training data, the code removes rows where any numeric feature or target is more than 3 standard deviations away from the mean (using z-score).

---

## 5. Visualization

```python
def plot_individual_performance(y_true, y_pred, target_name):
    """Generate separate analysis for each target parameter."""
    plt.figure(figsize=(12, 5))

    # Plot: Actual vs Predicted (with regression line)
    plt.subplot(1, 2, 1)
    sns.regplot(x=y_true, y=y_pred, scatter_kws={'alpha': 0.3})
    plt.title(f'{target_name} - Actual vs Predicted')
    plt.xlabel('Actual')
    plt.ylabel('Predicted')

    # Plot: Error Distribution
    plt.subplot(1, 2, 2)
    errors = y_true - y_pred
    sns.histplot(errors, kde=True)
    plt.title(f'{target_name} Error Distribution')
    plt.tight_layout()
    plt.savefig(f"{target_name}_performance.png")
    plt.close()
```

### Explanation:
- **Purpose:**
  Creates two plots for a given target:
  - A scatter plot with a regression line comparing actual vs. predicted values.
  - A histogram (with KDE) of the errors (differences between actual and predicted).
- **Output:**
  Saves each target’s performance plot as a PNG file named after the target.

---

## 6. Model Architecture Definition

```python
def create_model(input_shape):
    inputs = Input(shape=(input_shape,))
    x = Dense(256, activation='relu', kernel_regularizer=Config.REGULARIZATION)(inputs)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)
    x = Dense(128, activation='relu', kernel_regularizer=Config.REGULARIZATION)(x)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)
    outputs = Dense(len(Config.TARGET_COLS))(x)
    return Model(inputs, outputs)
```

### Explanation:
- **Input Layer:**
  Expects an input vector with a size equal to the number of features (here, 9).
- **Hidden Layers:**
  - First Dense layer with 256 neurons and ReLU activation, plus L1/L2 regularization.
  - Batch normalization and dropout (30%) help with training stability and reduce overfitting.
  - A second Dense layer with 128 neurons is similarly regularized and normalized.
- **Output Layer:**
  A Dense layer with a number of neurons equal to the number of target values (here, 2), which outputs the predicted dB values.

---

## 7. Training Pipeline (main function)

```python
def main():
    # Data Loading:
    train_df = load_data('/home/kayode-olalere/PycharmProjects/Project ANN/Training_set/New_Training_set.csv', is_generated=False)
    generated_df = load_data('/home/kayode-olalere/PycharmProjects/Project ANN/Codebase/Data_Gen/generated_input_dataset.csv', is_generated=True)

    # Data Preparation:
    X = train_df[Config.FEATURE_COLS].values.astype('float32')
    y = train_df[Config.TARGET_COLS].values.astype('float32')

    # Data Splitting:
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=Config.TEST_SIZE, random_state=Config.SEED)
    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=Config.VAL_SIZE, random_state=Config.SEED)

    # Feature Scaling:
    scaler = RobustScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    X_test_scaled = scaler.transform(X_test)
    joblib.dump(scaler, 'scaler.pkl')

    # MLflow Setup:
    mlflow.set_tracking_uri("mlruns")
    mlflow.tensorflow.autolog()

    # Training Block:
    with mlflow.start_run():
        # Model Creation and Compilation:
        model = create_model(X_train_scaled.shape[1])
        model.compile(optimizer=Adam(0.001), loss='mse', metrics=['mae'])

        # Callbacks:
        callbacks = [
            EarlyStopping(patience=Config.EARLY_STOPPING_PATIENCE, restore_best_weights=True),
            ReduceLROnPlateau(patience=Config.REDUCE_LR_PATIENCE, factor=0.5),
            ModelCheckpoint(Config.CHECKPOINT_PATH, save_best_only=True)
        ]

        # Model Training:
        history = model.fit(
            X_train_scaled, y_train,
            validation_data=(X_val_scaled, y_val),
            epochs=Config.EPOCHS,
            batch_size=Config.BATCH_SIZE,
            callbacks=callbacks,
            verbose=1
        )

        # Evaluation:
        test_pred = model.predict(X_test_scaled)
        r2_scores = [r2_score(y_test[:, i], test_pred[:, i]) for i in range(2)]
        mae_scores = [mean_absolute_error(y_test[:, i], test_pred[:, i]) for i in range(2)]
        print("\n=== Final Performance ===")
        print(f"Overall Accuracy: {np.mean(r2_scores) * 100:.1f}%")
        print(f"Average Error: {np.mean(mae_scores):.2f} dB")
        print("\nParameter-wise Performance:")
        for i, target in enumerate(Config.TARGET_COLS):
            print(f"{target}:")
            print(f"- Accuracy: {r2_scores[i] * 100:.1f}%")
            print(f"- Average Error: {mae_scores[i]:.2f} dB")
            plot_individual_performance(y_test[:, i], test_pred[:, i], target)

        # Frequency Analysis Visualization:
        plt.figure(figsize=(10, 6))
        for target in Config.TARGET_COLS:
            sns.lineplot(x=train_df['freq'], y=train_df[target], label=target, errorbar=None)
        plt.title("Frequency Response")
        plt.xlabel("Frequency (MHz)")
        plt.ylabel("dB Magnitude")
        plt.legend()
        plt.savefig("frequency_response.png")
        plt.close()

        # Generating Predictions on New Data:
        gen_inputs = generated_df[Config.FEATURE_COLS].values.astype('float32')
        gen_pred = model.predict(scaler.transform(gen_inputs))
        generated_df[Config.TARGET_COLS] = gen_pred
        generated_df.to_csv("antenna_predictions.csv", index=False)

if __name__ == "__main__":
    main()
```

### Explanation:

#### Data Loading and Splitting
- **train_df and generated_df:**
  Loads the training and generated data. For training data, the code skips the metadata row and applies proper column names; for generated data, it uses the file’s header and drops the “ID” column.
- **Feature and Target Extraction:**
  Extracts feature columns (9 features) and target columns (2 dB values) from the training data.
- **Data Splitting:**
  Uses scikit-learn’s `train_test_split` to divide the data into training, validation, and testing sets.

#### Feature Scaling
- **RobustScaler:**
  Scales the training features (to reduce the influence of outliers) and then transforms validation and test sets accordingly. The scaler is saved via joblib for later inference.

#### MLflow Integration
- **mlflow.set_tracking_uri and mlflow.tensorflow.autolog():**
  Sets up MLflow to track experiment parameters, metrics, and the model training process automatically.

#### Model Training
- **Model Creation and Compilation:**
  Builds the model using `create_model` with the input shape based on the number of features and compiles it using the Adam optimizer and mean squared error loss.
- **Callbacks:**
  Includes EarlyStopping, ReduceLROnPlateau, and ModelCheckpoint to improve training stability and prevent overfitting.
- **Training Loop:**
  Trains the model with the training data, validating on the validation set.

#### Evaluation and Visualization
- **Metrics Calculation:**
  Uses R² and MAE to evaluate model performance on the test set.
- **Visualization:**
  Generates plots:
  - For each target, actual vs. predicted scatter plots and error histograms are saved.
  - A frequency response plot is generated to analyze how the targets vary with frequency.
- **Predictions on Generated Data:**
  Applies the trained model to the generated dataset (after scaling) and saves the results to a CSV file.

---

## 8. Summary

- **Modular Design:**
  The code is broken into functions for data parsing, loading, visualization, model creation, and the training pipeline.
- **Preprocessing:**
  Special attention is given to handling frequency strings and scaling input features.
- **Model Definition:**
  A simple feed-forward neural network is defined with two hidden layers, using dropout and batch normalization.
- **Experiment Tracking:**
  MLflow is used to log training details, while joblib ensures that the scaler used during training is saved.
- **Evaluation:**
  The code computes common regression metrics and produces visualizations for further analysis.
- **Deployment:**
  After training, the model is used to generate predictions on new data, which are then saved for later use.

