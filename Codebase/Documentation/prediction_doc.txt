# Documentation for Using a Trained Neural Network for Prediction

This documentation outlines the process of using a pre-trained artificial neural network (ANN) model to make predictions on new input data. It explains each step, from loading the model and preparing the scaler to scaling new data and obtaining predictions.

---

## **Overview**
The script utilizes a pre-trained ANN model (`best_model_advanced.h5`) to predict outputs (`S1` and `S2`) based on six input features. It follows these key steps:

1. Load the trained ANN model.
2. Fit a `StandardScaler` on the original training data.
3. Scale new input data to match the model's input format.
4. Use the model to generate predictions for the scaled input data.

---

## **Key Components**

### **1. Dependencies**
- **NumPy:** For handling arrays and numerical operations.
- **Pandas:** For reading and processing CSV files.
- **TensorFlow/Keras:** For loading and using the pre-trained model.
- **Scikit-learn:** For scaling the input features using `StandardScaler`.

---

## **Detailed Steps**

### **1. Load the Pre-trained Model**
- The trained model (`best_model_advanced.h5`) is loaded using Keras’s `load_model()` function.
- This model is saved in the directory:
  `/home/kayode-olalere/PycharmProjects/Project ANN/Codebase/Model/VER_2/best_model_advanced.h5`.

### **2. Load the Original Training Data**
- The training data is loaded from a CSV file:
  `/home/kayode-olalere/PycharmProjects/Project ANN/Model/Formatted_Training_Data.csv`.
- The script extracts six numeric features (columns 1 to 6) from the training data using Pandas.

**Note:** The first column is assumed to be non-relevant (e.g., an index or serial number). Non-numeric data is coerced to `NaN`, and rows with missing values are dropped.

```python
X_train = df.iloc[:, 1:7].apply(pd.to_numeric, errors='coerce').dropna().values
```

### **3. Fit the Scaler on Training Data**
- A `StandardScaler` is used to standardize the training data.
- The scaler ensures that the input data is normalized to have a mean of 0 and a standard deviation of 1, matching the model’s expectations.

```python
scaler = StandardScaler()
scaler.fit(X_train)
```

### **4. Define and Scale New Input Data**
- New data for predictions is provided as a NumPy array with six input features:
  ```python
  new_data = np.array([[1.29, 4.53, 3.9, 0.21, 0.49, 3.71]])
  ```
- The new data is scaled using the `StandardScaler` fitted on the training data:
  ```python
  new_data_scaled = scaler.transform(new_data)
  ```

### **5. Make Predictions**
- The pre-trained model is used to generate predictions for the scaled input data:
  ```python
  predictions = model.predict(new_data_scaled)
  print("Predictions:", predictions)
  ```
- The output is a NumPy array containing predictions for `S1` and `S2`.

---

## **Outputs**
- The script prints the predictions for the new input data in the format:
  ```
  Predictions: [[S1_pred, S2_pred]]
  ```

---

## **Assumptions and Notes**
1. **Input Features:**
   The model expects exactly six input features, which must be numeric.
2. **Training Data:**
   The `StandardScaler` is fit on the original training data to ensure consistency in scaling.
3. **Error Handling:**
   - Rows with missing or non-numeric values in the training data are dropped.
   - The `apply(pd.to_numeric, errors='coerce')` ensures invalid data types are converted to `NaN`.

---

## **Usage Instructions**
1. Ensure the following files are available:
   - `best_model_advanced.h5`: The pre-trained model.
   - `Formatted_Training_Data.csv`: The training dataset used to fit the scaler.

2. Place the script and these files in the correct directory paths.

3. Modify the `new_data` array to include the input values you wish to predict for.

4. Run the script to see the predictions for `S1` and `S2`.

---